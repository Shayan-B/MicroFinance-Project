{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling\n",
    "\n",
    "In this Notebook, we address the classification problem using various machine learning algorithms while handling the highly imbalanced nature of the target variable. We evaluate the performance of each model and select the best-performing one for further analysis.\n",
    "\n",
    "In a data science project, modeling is a pivotal phase that significantly contributes to the project's success. It serves as a bridge between the insights gained from exploratory data analysis (EDA) and the practical application of predictive analytics. Through modeling, we delve deeper into the dataset, uncovering intricate patterns, relationships, and trends that may not be readily discernible through initial data exploration alone.\n",
    "\n",
    "The essence of modeling lies in its ability to harness the power of various machine learning algorithms to extract actionable insights and make accurate predictions. These algorithms encompass a wide range of techniques, from simple linear regression to complex ensemble methods, each tailored to address specific aspects of the data and the problem at hand.\n",
    "\n",
    "In a classification problem characterized by a highly imbalanced target variable, effective modeling techniques are particularly crucial. Imbalance in the class distribution can skew the learning process of machine learning algorithms, leading to biased predictions and poor performance, especially for minority classes. Therefore, employing appropriate modeling strategies becomes imperative to accurately classify instances belonging to the minority class while maintaining overall predictive performance.\n",
    "\n",
    "Through careful selection and tuning of machine learning algorithms, along with the implementation of advanced techniques such as data resampling and hyperparameter tuning, we strive to develop robust models capable of effectively handling class imbalance. These models not only enhance the predictive accuracy but also provide valuable insights into the underlying dynamics of the data, empowering stakeholders to make informed decisions and take proactive measures.\n",
    "\n",
    "Outline of the notebook will be as written below:\n",
    "- Model Selection\n",
    "- Data Resampling\n",
    "- Model Training\n",
    "- Model Evaluation\n",
    "- Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from src import micro_modeling as modeling\n",
    "from src import micro\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously cleaned data\n",
    "train_df = micro.read_parquet_file(dir_name=\"original_data\", file_name=\"application_train\")\n",
    "# train_df = micro.read_parquet_file(dir_name=\"cleaned_data\", file_name=\"cleaned_train_data\")\n",
    "# test_df = micro.read_parquet_file(dir_name=\"cleaned_data\", file_name=\"cleaned_test_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Model Selection\n",
    "\n",
    "We consider a range of machine learning algorithms suitable for imbalanced classification problems, including but not limited to:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Support Vector Machines (with class weights or oversampling techniques)\n",
    "- Ensemble methods (such as Bagging and Boosting)\n",
    "\n",
    "The selection of models is based on their ability to handle class imbalance, interpretability, and computational efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Data Resampling\n",
    "\n",
    "Given the highly imbalanced nature of the target variable, we employ data resampling techniques to address class imbalance. These techniques include:\n",
    "\n",
    "- Oversampling of the minority class (e.g., using SMOTE or ADASYN)\n",
    "- Undersampling of the majority class\n",
    "- Synthetic data generation\n",
    "- Ensemble methods (such as EasyEnsemble or BalancedBaggingClassifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Model Training\n",
    "\n",
    "We split the preprocessed dataset into training and testing sets with a ratio of 70-30. The training set is used to train the models, while the testing set is used for model evaluation. Also we will use the StratifiedKFold splitting in order to make sure that the imbalance in the `TARGET` won't affect the training so much.\n",
    "\n",
    "We train each selected model using the resampled training dataset and assess their performance using appropriate evaluation metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Model Evaluation\n",
    "\n",
    "We evaluate the performance of each model using the following evaluation metrics, considering the imbalanced nature of the dataset:\n",
    "\n",
    "- Precision, Recall, F1-score, and ROC AUC\n",
    "- Average Precision (AP) and Area under Precision-Recall Curve (PR AUC)\n",
    "- Confusion matrices with emphasis on true positive and false positive rates\n",
    "\n",
    "Additionally, we visualize the model's performance using:\n",
    "\n",
    "- Precision-Recall curves\n",
    "- ROC curves\n",
    "- Confusion matrices\n",
    "- Calibration plots\n",
    "\n",
    "We do the Model training and evaluation with each other using the cross_val_score of the sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models list\n",
    "models = [DecisionTreeClassifier, RandomForestClassifier, LogisticRegression, SVC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [DecisionTreeClassifier, RandomForestClassifier, LogisticRegression, SVC]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling.evaluate_models(train_df, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Hyperparameter Tuning\n",
    "\n",
    "We conduct hyperparameter tuning to optimize the performance of the selected models, considering their ability to handle class imbalance. This involves:\n",
    "\n",
    "- Performing grid search or randomized search over a range of hyperparameters.\n",
    "- Using stratified cross-validation to maintain the class distribution during hyperparameter tuning.\n",
    "- Tuning hyperparameters based on performance metrics such as F1-score, ROC AUC, or average precision.\n",
    "\n",
    "## 4.6 Model Selection and Interpretation\n",
    "\n",
    "Based on the evaluation results, we select the best-performing model for further analysis. We interpret the model's coefficients, feature importance scores, and other relevant factors to understand the underlying relationships captured by the model.\n",
    "\n",
    "## 4.7 Model Validation\n",
    "\n",
    "Finally, we validate the selected model using the testing dataset to ensure its generalization performance. We assess the model's performance on unseen data and compare it with the training performance to check for overfitting or underfitting.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
